{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow.compat.v1 as tf\n",
    "import SimpleITK as sitk\n",
    "import nibabel\n",
    "import nibabel.processing\n",
    "import argparse\n",
    "from scipy.ndimage import zoom\n",
    "tf.disable_v2_behavior()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class auto_encoder(object):\n",
    "    def __init__(self, sess):\n",
    "        self.sess           = sess\n",
    "        self.phase          = 'train'\n",
    "        self.batch_size     = 1\n",
    "        self.inputI_size    = 128\n",
    "        self.inputI_chn     = 1\n",
    "        self.output_chn     = 12\n",
    "        self.lr             = 0.0001\n",
    "        self.beta1          = 0.3\n",
    "        self.epoch          = 500\n",
    "        self.model_name     = 'n1.model'\n",
    "        self.save_intval    = 20\n",
    "        self.build_model()\n",
    "        self.chkpoint_dir   = \"./ckpt\"\n",
    "        self.train_data_dir = \"./real_train/incomplete/\"\n",
    "        self.train_label_dir = \"./real_train/complete\"\n",
    "        self.test_data_dir = \"./real_test/incomplete\"\n",
    "\n",
    "        self.test_label_dir=\"./Dtest4/dataset/0_ground_truth/lung/\"\n",
    "        self.save_output_dir = \"./output_multiclass/\"\n",
    "        self.save_residual_dir = \"./output_multiclass/residual/\"\n",
    "\n",
    "\n",
    "    def dice_loss_fun(self, pred, input_gt):\n",
    "        input_gt = tf.one_hot(input_gt, 12)\n",
    "        dice = 0\n",
    "        for i in range(12):\n",
    "            inse = tf.reduce_mean(pred[:, :, :, :, i]*input_gt[:, :, :, :, i])\n",
    "            l = tf.reduce_sum(pred[:, :, :, :, i]*pred[:, :, :, :, i])\n",
    "            r = tf.reduce_sum(input_gt[:, :, :, :, i] * input_gt[:, :, :, :, i])\n",
    "            dice = dice + 2*inse/(l+r)\n",
    "        return -dice\n",
    "\n",
    "\n",
    "\n",
    "    def conv3d(self,input, output_chn, kernel_size, stride, use_bias=False, name='conv'):\n",
    "        return tf.layers.conv3d(inputs=input, filters=output_chn, kernel_size=kernel_size, strides=stride,\n",
    "                                padding='same', data_format='channels_last',\n",
    "                                kernel_initializer=tf.truncated_normal_initializer(0.0, 0.01),use_bias=use_bias, name=name)\n",
    "\n",
    "\n",
    "    def conv_bn_relu(self,input, output_chn, kernel_size, stride, use_bias, is_training, name):\n",
    "        with tf.variable_scope(name):\n",
    "            conv = self.conv3d(input, output_chn, kernel_size, stride, use_bias, name='conv')\n",
    "            relu = tf.nn.relu(conv, name='relu')\n",
    "        return relu\n",
    "\n",
    "\n",
    "\n",
    "    def Deconv3d(self,input, output_chn, name):\n",
    "        batch, in_depth, in_height, in_width, in_channels = [int(d) for d in input.get_shape()]\n",
    "        filter = tf.get_variable(name+\"/filter\", shape=[4, 4, 4, output_chn, in_channels], dtype=tf.float32,\n",
    "                                 initializer=tf.random_normal_initializer(0, 0.01))\n",
    "        conv = tf.nn.conv3d_transpose(value=input, filter=filter, output_shape=[batch, in_depth * 2, in_height * 2, in_width * 2, output_chn],\n",
    "                                      strides=[1, 2, 2, 2, 1], padding=\"SAME\", name=name)\n",
    "        return conv\n",
    "\n",
    "\n",
    "\n",
    "    def deconv_bn_relu(self,input, output_chn, is_training, name):\n",
    "        with tf.variable_scope(name):\n",
    "            conv = self.Deconv3d(input, output_chn, name='deconv')\n",
    "            relu = tf.nn.relu(conv, name='relu')\n",
    "        return relu\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def build_model(self):\n",
    "        print('building patch based model...')       \n",
    "        self.input_I = tf.placeholder(dtype=tf.float32, shape=[self.batch_size,self.inputI_size,self.inputI_size,128, self.inputI_chn], name='inputI')\n",
    "        self.input_gt = tf.placeholder(dtype=tf.int64, shape=[self.batch_size,self.inputI_size,self.inputI_size,128,1], name='target')\n",
    "        self.soft_prob , self.task0_label = self.encoder_decoder(self.input_I)\n",
    "        self.main_dice_loss = self.dice_loss_fun(self.soft_prob, self.input_gt[:,:,:,:,0])\n",
    "        self.dice_loss=200000000*self.main_dice_loss\n",
    "        self.Loss = self.dice_loss\n",
    "        self.saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "    def encoder_decoder(self, inputI):\n",
    "        phase_flag = (self.phase=='train')\n",
    "        conv1_1 = self.conv3d(input=inputI, output_chn=64, kernel_size=3, stride=2, use_bias=True, name='conv1')\n",
    "        conv1_relu = tf.nn.relu(conv1_1, name='conv1_relu')\n",
    "        conv2_1 = self.conv3d(input=conv1_relu, output_chn=128, kernel_size=3, stride=2, use_bias=True, name='conv2')\n",
    "        conv2_relu = tf.nn.relu(conv2_1, name='conv2_relu')\n",
    "        conv3_1 = self.conv3d(input=conv2_relu, output_chn= 256, kernel_size=3, stride=2, use_bias=True, name='conv3a')\n",
    "        conv3_relu = tf.nn.relu(conv3_1, name='conv3_1_relu')\n",
    "        conv4_1 = self.conv3d(input=conv3_relu, output_chn=512, kernel_size=3, stride=2, use_bias=True, name='conv4a')\n",
    "        conv4_relu = tf.nn.relu(conv4_1, name='conv4_1_relu')\n",
    "        conv5_1 = self.conv3d(input=conv4_relu, output_chn=512, kernel_size=3, stride=1, use_bias=True, name='conv5a')\n",
    "        conv5_relu = tf.nn.relu(conv5_1, name='conv5_1_relu')\n",
    "        feature= self.conv_bn_relu(input=conv5_relu, output_chn=256, kernel_size=3, stride=1, use_bias=True, is_training=phase_flag, name='conv6_1')\n",
    "        deconv1_1 = self.deconv_bn_relu(input=feature, output_chn=256, is_training=phase_flag, name='deconv1_1')\n",
    "        deconv1_2 = self.conv_bn_relu(input=deconv1_1, output_chn=128, kernel_size=3, stride=1, use_bias=True, is_training=phase_flag, name='deconv1_2')\n",
    "        deconv2_1 = self.deconv_bn_relu(input=deconv1_2, output_chn=128, is_training=phase_flag, name='deconv2_1')\n",
    "        deconv2_2 = self.conv_bn_relu(input=deconv2_1, output_chn=64, kernel_size=3,stride=1, use_bias=True, is_training=phase_flag, name='deconv2_2')\n",
    "        deconv3_1 = self.deconv_bn_relu(input=deconv2_2, output_chn=64, is_training=phase_flag, name='deconv3_1')\n",
    "        deconv3_2 = self.conv_bn_relu(input=deconv3_1, output_chn=64, kernel_size=3, stride=1, use_bias=True, is_training=phase_flag, name='deconv3_2')\n",
    "        deconv4_1 = self.deconv_bn_relu(input=deconv3_2, output_chn=32, is_training=phase_flag, name='deconv4_1')\n",
    "        deconv4_2 = self.conv_bn_relu(input=deconv4_1, output_chn=32, kernel_size=3, stride=1, use_bias=True, is_training=phase_flag, name='deconv4_2')\n",
    "        pred_prob1 = self.conv_bn_relu(input=deconv4_2, output_chn=self.output_chn, kernel_size=3, stride=1, use_bias=True, is_training=phase_flag, name='pred_prob1')\n",
    "        pred_prob = self.conv3d(input=pred_prob1, output_chn=self.output_chn, kernel_size=3, stride=1, use_bias=True, name='pred_prob')\n",
    "        pred_prob2 = self.conv3d(input=pred_prob, output_chn=self.output_chn, kernel_size=3, stride=1, use_bias=True, name='pred_prob2')\n",
    "        pred_prob3 = self.conv3d(input=pred_prob2, output_chn=self.output_chn, kernel_size=3, stride=1, use_bias=True, name='pred_prob3')\n",
    "        soft_prob=tf.nn.softmax(pred_prob3,name='task_0')\n",
    "        task0_label=tf.argmax(soft_prob,axis=4,name='argmax0')\n",
    "        return  soft_prob,task0_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def train(self):\n",
    "        u_optimizer = tf.train.AdamOptimizer(learning_rate=self.lr, beta1=self.beta1).minimize(self.Loss)\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        self.sess.run(init_op)\n",
    "        counter=1\n",
    "\n",
    "        train_label_list=glob('{}/*.nii.gz'.format(self.train_label_dir))\n",
    "\n",
    "        i=0\n",
    "        for epoch in np.arange(self.epoch):\n",
    "            i=i+1\n",
    "            print('epoch:',i )\n",
    "            for j in range(len(train_label_list)):\n",
    "                labelImg=sitk.ReadImage(train_label_list[j])\n",
    "                labelNpy=sitk.GetArrayFromImage(labelImg)\n",
    "                labelNpy_resized=zoom(labelNpy,(128/labelNpy.shape[0],128/labelNpy.shape[1],128/labelNpy.shape[2]),order=0, mode='constant')\n",
    "                labelNpy_resized=np.expand_dims(np.expand_dims(labelNpy_resized,axis=0),axis=4) \n",
    "                name=train_label_list[j][-len('_full.nii.gz')-len('s0556'):-len('_full.nii.gz')]\n",
    "                for k in range(10):\n",
    "                    data_dir=self.train_data_dir+str(name)+'./'+str(name)+'_%d'%k+'.nii.gz'\n",
    "                    trainImg=sitk.ReadImage(data_dir)\n",
    "                    trainNpy=sitk.GetArrayFromImage(trainImg)\n",
    "                    trainNpy_resized=zoom(trainNpy,(128/trainNpy.shape[0],128/trainNpy.shape[1],128/trainNpy.shape[2]),order=0, mode='constant')\n",
    "                    trainNpy_resized=np.expand_dims(np.expand_dims(trainNpy_resized,axis=0),axis=4) \n",
    "                    _, cur_train_loss = self.sess.run([u_optimizer, self.Loss], feed_dict={self.input_I: trainNpy_resized, self.input_gt: labelNpy_resized})\n",
    "                    train_output0 = self.sess.run(self.task0_label, feed_dict={self.input_I: trainNpy_resized})\n",
    "                    print('sum for current training whole: %.8f, pred whole:  %.8f'%(np.sum(labelNpy_resized),np.sum(train_output0)))        \n",
    "                    print('current training loss:',cur_train_loss)\n",
    "            counter+=1\n",
    "            if np.mod(counter, self.save_intval) == 0:\n",
    "                self.save_chkpoint(self.chkpoint_dir, self.model_name, counter)\n",
    "\n",
    "        self.save_chkpoint(self.chkpoint_dir, self.model_name, counter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def test(self):\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        self.sess.run(init_op)\n",
    "        if self.load_chkpoint(self.chkpoint_dir):\n",
    "            print(\" *****Successfully load the checkpoint**********\")\n",
    "        else:\n",
    "            print(\"*******Fail to load the checkpoint***************\")\n",
    "\n",
    "        test_list=glob('{}/*.nii.gz'.format(self.test_data_dir))\n",
    "\n",
    "        k=1\n",
    "        for i in range(len(test_list)):\n",
    "\n",
    "            ### input \n",
    "            print(test_list[i])                    \n",
    "            test_img=sitk.ReadImage(test_list[i])\n",
    "            test_input = sitk.GetArrayFromImage(test_img)\n",
    "            test_input_resized_ = zoom(test_input,(256/test_input.shape[0],256/test_input.shape[1],128/test_input.shape[2]),order=0, mode='constant')\n",
    "            test_input_resized_[test_input_resized_>12]=0\n",
    "            test_input_resized_[test_input_resized_<0]=0\n",
    "            print('test_input_resized_',np.unique(test_input_resized_))\n",
    "            test_input_resized=np.expand_dims(np.expand_dims(test_input_resized_,axis=0),axis=4)\n",
    "\n",
    "\n",
    "            ## prediction\n",
    "            test_output = self.sess.run(self.task0_label, feed_dict={self.input_I: test_input_resized})\n",
    "            print(test_output.shape)\n",
    "            print(np.unique(test_output))\n",
    "\n",
    "\n",
    "            ## output\n",
    "            filename=self.save_output_dir+test_list[i][-7-len('s0332_0'):-7]+'.nii.gz'\n",
    "            resize2original=1\n",
    "\n",
    "            if resize2original:\n",
    "                print('resizing predictions...')\n",
    "\n",
    "                test_output=zoom(test_output[0],(test_input.shape[0]/256,test_input.shape[1]/256,test_input.shape[2]/128),order=0, mode='constant')\n",
    "                print(test_output.shape)\n",
    "\n",
    "                test_output[test_output>12]=0\n",
    "                test_output[test_output<0]=0\n",
    "                test_pred=sitk.GetImageFromArray(test_output.astype('int32'))\n",
    "                test_pred.CopyInformation(test_img)\n",
    "                sitk.WriteImage(test_pred,filename)\n",
    "\n",
    "            else:\n",
    "                print('resizing input...')\n",
    "                #test_img_downsampled=self.downsamplePatient(test_img,test_input.shape[0]/256,test_input.shape[1]/256,test_input.shape[2]/128)\n",
    "                print('resizing done...')\n",
    "\n",
    "                input_img = nibabel.load(test_list[i])\n",
    "\n",
    "                voxel_size=input_img.header.get_zooms()\n",
    "                voxel_size_new=[voxel_size[0]*(test_input.shape[0]/256),voxel_size[1]*(test_input.shape[1]/256),voxel_size[2]*(test_input.shape[2]/128)]\n",
    "                resampled_img = nibabel.processing.resample_to_output(input_img, voxel_size_new)\n",
    "                filename_img=self.save_output_dir+test_list[i][-7-len('s0332_0'):-7]+'_org'+'.nii.gz'\n",
    "                nibabel.save(resampled_img, filename_img)\n",
    "\n",
    "\n",
    "                test_pred=sitk.GetImageFromArray(test_output[0].astype('int32'))\n",
    "                sitk.WriteImage(test_pred,filename)\n",
    "\n",
    "\n",
    "            k+=1\n",
    "            #filename_res=self.save_residual_dir+test_list[i][-7-len('s0332_0'):-7]+'.nii.gz'\n",
    "            #res_output=test_output-test_input\n",
    "            #res_output_img=sitk.GetImageFromArray(res_output.astype('int32'))\n",
    "            #res_output_img.CopyInformation(test_img)\n",
    "            #sitk.WriteImage(res_output_img,filename_res)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def save_chkpoint(self, checkpoint_dir, model_name, step):\n",
    "        model_dir = \"%s\" % ('ckpt')\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "        self.saver.save(self.sess, os.path.join(checkpoint_dir, model_name), global_step=step)\n",
    "\n",
    "\n",
    "\n",
    "    def load_chkpoint(self, checkpoint_dir):\n",
    "        print(\" [*] Reading checkpoint...\")\n",
    "        model_dir = \"%s\" % ('ckpt')\n",
    "        print('########################################################')\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--phase\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    sess1 = tf.compat.v1.Session()\n",
    "    with sess1.as_default():\n",
    "        with sess1.graph.as_default():\n",
    "            model = auto_encoder(sess1)\n",
    "            total_parameters = 0\n",
    "            for variable in tf.trainable_variables():\n",
    "                shape = variable.get_shape()\n",
    "                variable_parameters = 1\n",
    "                for dim in shape:\n",
    "                    variable_parameters *= dim.value\n",
    "                total_parameters += variable_parameters\n",
    "            print('trainable params:',total_parameters)\n",
    "\n",
    "    if args.phase == \"train\":\n",
    "        print('training model...')\n",
    "        model.train()\n",
    "    if args.phase == \"test\":\n",
    "        print('testing model...')\n",
    "        model.test()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
